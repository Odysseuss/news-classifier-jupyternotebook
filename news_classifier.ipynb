{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('uci-news-aggregator.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422419 observations \n",
      "8 features\n",
      "11236 unique sites from which the training data was extrapolated\n"
     ]
    }
   ],
   "source": [
    "print(\"{} observations \\n{} features\".format(dataset.shape[0], dataset.shape[1]))\n",
    "print(\"{} unique sites from which the training data was extrapolated\".format(len(dataset.HOSTNAME.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME',\n",
      "       'TIMESTAMP'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pick our feature set (X) and what we are trying to predict (y)\n",
    "X = dataset.TITLE\n",
    "y = dataset.CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Sample of X\n",
      "\n",
      "254791    ECB says it is ready to take action if low inf...\n",
      "394087    Facebook Forces iPhone Users To Separate Messa...\n",
      "158243    FDA to hit e-cigarettes with ban on sales to a...\n",
      "286386    Destiny is “Good Fit” for PC – Activision Publ...\n",
      "93248     Peter Mayhew Set to Return as Chewbacca in Sta...\n",
      "Name: TITLE, dtype: object\n",
      "\n",
      "\n",
      "\t\t Sample of y (No relation to the X sample)\n",
      "\n",
      "57900     t\n",
      "180126    b\n",
      "420392    e\n",
      "145967    e\n",
      "89686     e\n",
      "Name: CATEGORY, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\t Sample of X\\n\")\n",
    "print(X.sample(5))\n",
    "print(\"\\n\\n\\t\\t Sample of y (No relation to the X sample)\\n\")\n",
    "print(y.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a helper function perform preprocessing on data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, sublinear_tf=True)\n",
    "vectorizer.fit(dataset.TITLE)\n",
    "\n",
    "def process_data(X, y, vectorizer):\n",
    "    y = pd.get_dummies(y)\n",
    "    X = vectorizer.transform(X)\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>e</th>\n",
       "      <th>m</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254802</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355755</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133464</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314011</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83420</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        b  e  m  t\n",
       "254802  1  0  0  0\n",
       "355755  0  0  1  0\n",
       "133464  0  0  0  1\n",
       "314011  0  0  1  0\n",
       "83420   0  0  1  0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = process_data(X_train, y_train, vectorizer)\n",
    "y_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "# Input layer\n",
    "classifier.add(Dense(units = 50, activation='relu', \n",
    "                     kernel_initializer = 'uniform',\n",
    "                     input_shape = (54637,)))\n",
    "\n",
    "# Four Hidden Layers\n",
    "classifier.add(Dense(units =50, activation='relu', \n",
    "                     kernel_initializer='uniform'))\n",
    "classifier.add(Dense(units =50, activation='relu', \n",
    "                     kernel_initializer='uniform'))\n",
    "classifier.add(Dense(units =50, activation='relu', \n",
    "                     kernel_initializer='uniform'))\n",
    "classifier.add(Dense(units =50, activation='relu', \n",
    "                     kernel_initializer='uniform'))\n",
    "\n",
    "# Output Layer. Four output nodes for our four classification types of news headlines.\n",
    "classifier.add(Dense(units = 4, activation='sigmoid', \n",
    "                     kernel_initializer='uniform'))\n",
    "\n",
    "classifier.compile(optimizer = 'rmsprop', loss ='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "337935/337935 [==============================] - 164s 485us/step - loss: 0.4474 - acc: 0.8248\n",
      "Epoch 2/5\n",
      "337935/337935 [==============================] - 168s 498us/step - loss: 0.2052 - acc: 0.9321\n",
      "Epoch 3/5\n",
      "337935/337935 [==============================] - 171s 507us/step - loss: 0.1729 - acc: 0.9438\n",
      "Epoch 4/5\n",
      "337935/337935 [==============================] - 172s 508us/step - loss: 0.1544 - acc: 0.9502\n",
      "Epoch 5/5\n",
      "337935/337935 [==============================] - 165s 488us/step - loss: 0.1430 - acc: 0.9548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f17abc1e908>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create files to store model configuration and weights\n",
    "# such that the model can be built back up from the files\n",
    "# rather than having to retrain.\n",
    "# Thanks to https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "config_filename = \"model_config\" + timestr + \".json\"\n",
    "weights_filename = \"model_weights\" + timestr + \".h5\"\n",
    "\n",
    "# Serialize model to JSON\n",
    "classifier_json = classifier.to_json()\n",
    "with open(config_filename, \"w\") as json_file:\n",
    "    json_file.write(classifier_json)\n",
    "\n",
    "# Serialize weights to HDF5\n",
    "classifier.save_weights(weights_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84484/84484 [==============================] - 19s 227us/step\n",
      "Model accuracy on test data = 0.9453032526868993 \n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = process_data(X_test, y_test, vectorizer)\n",
    "\n",
    "scores = classifier.evaluate(X_test, y_test)\n",
    "print(\"Model accuracy on test data = {} \".format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function that takes in a prediction from our classifier and prints out the\n",
    "# associated category\n",
    "def get_predicted_headline_category(prediction):\n",
    "    type_mapping = {0: 'Business', 1: 'Entertainment', 2: 'Health', 3: 'Science and Technology'}\n",
    "    return type_mapping[prediction.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Science and Technology] SpaceX Not to Blame for Zuma Spy-Satellite Launch Failure: Report \n",
      "\n",
      "[Entertainment] An Ultra-Powerful Flare Erupted From Our Nearest Neighbor Star \n",
      "\n",
      "[Science and Technology] NASA Begins Building Next Mars Rover for 2020 Launch \n",
      "\n",
      "[Science and Technology] Hubble Telescope Discovers a Light-Bending 'Einstein Ring' in Space \n",
      "\n",
      "[Science and Technology] If 'Oumuamua Is an Alien Spacecraft, It's Keeping Quiet So Far \n",
      "\n",
      "[Science and Technology] Antarctic snowfall increasing, study finds \n",
      "\n",
      "[Science and Technology] Giant Ichthyosaur: 205-Million-Year-Old Jawbone Discovered From 'One of Largest Animals Ever' \n",
      "\n",
      "[Science and Technology] No, Buzz Aldrin didn't see a UFO on his way to the moon \n",
      "\n",
      "[Science and Technology] The new biggest marine reptile ever found \n",
      "\n",
      "[Science and Technology] Prehistoric Sea Monster Is One Of The Largest Animals Ever \n",
      "\n",
      "[Entertainment] The heart of the Milky Way teems with black holes \n",
      "\n",
      "[Science and Technology] NASA Sends Human Sperm to the International Space Station \n",
      "\n",
      "[Science and Technology] Buzz Aldrin's son unveils giant Mars maps for Spartanburg students \n",
      "\n",
      "[Science and Technology] Universe's Earliest Light Reveals Dark-Matter \"Superhighway\" 100's of Millions of Light Years Long \n",
      "\n",
      "[Science and Technology] This could be why our eyebrows evolved \n",
      "\n",
      "[Science and Technology] New Netflix Doc 'Mercury 13' Tells the Story of NASA's Other Hidden Figures \n",
      "\n",
      "[Science and Technology] Pinson Valley High School makes contact with astronaut on International Space Station \n",
      "\n",
      "[Science and Technology] NASA's Next Great Planet Hunter Has Arrived \n",
      "\n",
      "[Science and Technology] Both marine and land heat waves can be deadly, but one lasts much longer \n",
      "\n",
      "[Science and Technology] To the moon and back - 'Rocket Men' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scrape some top story article headlines and run them through our classifier\n",
    "# Thanks to https://www.w3resource.com/python-exercises/basic/python-basic-1-exercise-8.php\n",
    "\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# URLS of known topics\n",
    "business_news_url=\"https://news.google.com/news/rss/headlines/section/topic/BUSINESS?ned=us&hl=en&gl=US\"\n",
    "tech_news_url = \"https://news.google.com/news/rss/headlines/section/topic/TECHNOLOGY?ned=us&hl=en&gl=US\"\n",
    "science_news_url = \"https://news.google.com/news/rss/headlines/section/topic/SCIENCE?ned=us&hl=en&gl=US\"\n",
    "health_news_url = \"https://news.google.com/news/rss/headlines/section/topic/HEALTH?ned=us&hl=en&gl=US\"\n",
    "entertainment_news_url = \"https://news.google.com/news/rss/headlines/section/topic/ENTERTAINMENT?ned=us&hl=en&gl=US\"\n",
    "\n",
    "news_url = science_news_url\n",
    "\n",
    "Client = urlopen(news_url)\n",
    "xml_page = Client.read()\n",
    "Client.close()\n",
    "\n",
    "soup_page=soup(xml_page,\"xml\")\n",
    "news_list=soup_page.findAll(\"item\")\n",
    "\n",
    "for news in news_list:\n",
    "    # Store the headline string\n",
    "    headline = news.title.text\n",
    "    \n",
    "    # Vectorize the headline string such that the classifier can make a prediction\n",
    "    vectorized_headline = vectorizer.transform([headline])\n",
    "    \n",
    "    # Make a prediction and get the resulting category\n",
    "    prediction = classifier.predict(vectorized_headline)\n",
    "    predicted_category = get_predicted_headline_category(prediction)\n",
    "    \n",
    "    # Print [<Prediction>] <Headline>\n",
    "    print(\"[{}] {} \\n\".format(predicted_category, headline))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
